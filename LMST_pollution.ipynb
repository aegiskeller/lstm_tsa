{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5a559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb26cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f5b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
      "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
      "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
      "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
      "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
      "\n",
      "   var7(t-1)  var8(t-1)   var1(t)  \n",
      "1   0.000000        0.0  0.148893  \n",
      "2   0.000000        0.0  0.159960  \n",
      "3   0.000000        0.0  0.182093  \n",
      "4   0.037037        0.0  0.138833  \n",
      "5   0.074074        0.0  0.109658  \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('input/lstm-datasets-multivariate-univariate/LSTM-Multivariate_pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14273b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32850, 1, 8) (32850,) (10949, 1, 8) (10949,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "#1#################################################\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 90\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "##################################################\n",
    "#2################################################\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_X, test_X,train_y, test_y = train_test_split(train, test, test_size = 0.2, random_state = 0)\n",
    "###################################################\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4693202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1174/1174 [==============================] - 4s 2ms/step - loss: 0.0417 - val_loss: 0.0167\n",
      "Epoch 2/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 3/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 4/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 5/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 6/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 7/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 8/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 9/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 10/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 11/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0132\n",
      "Epoch 12/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 13/40\n",
      "1174/1174 [==============================] - 2s 2ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 14/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 15/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 16/40\n",
      "1174/1174 [==============================] - 2s 2ms/step - loss: 0.0141 - val_loss: 0.0130\n",
      "Epoch 17/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 18/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0133\n",
      "Epoch 19/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 20/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 21/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 22/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 23/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0132\n",
      "Epoch 24/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 25/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 26/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 27/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 28/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 29/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 30/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 31/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 32/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 33/40\n",
      "1174/1174 [==============================] - 2s 1ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 34/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0136\n",
      "Epoch 35/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 36/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 37/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 38/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 39/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 40/40\n",
      "1174/1174 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0137\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(15, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=40, batch_size=28, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf2df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "#inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6018109d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4140/874954987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# calculate RMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test RMSE: %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0m\u001b[0;32m    100\u001b[0m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=8)"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "so this equates to an average error of 26 over a median value of 70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.median(inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a450b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(inv_y, label='obs')\n",
    "pyplot.plot(inv_yhat, label='pred')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d862a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
